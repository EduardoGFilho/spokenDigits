Found 220 files with extension wav in folder ../wav
Label Histogram:
['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
[20 16 18 20 19 24 18 26 38 21]
Wrote file ../general/wavs_labels.csv
Wrote file ../general/labels_dictionary.json
Created output folder for plots in png format ../outputs/1melD18T30/features_melD18T30
Saved file ../outputs/1melD18T30/general_frontend_commandline_args.txt
7 from 7_lucas_10.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_10_fea.pkl
5 from 5_george_44.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_44_fea.pkl
6 from 6_jackson_14.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_14_fea.pkl
6 from 6_jackson_2.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_2_fea.pkl
9 from 9_jackson_24.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_24_fea.pkl
1 from 1_george_5.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_5_fea.pkl
9 from 9_jackson_42.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_42_fea.pkl
3 from 3_george_16.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_16_fea.pkl
6 from 6_jackson_3.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_3_fea.pkl
8 from 8_george_47.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_47_fea.pkl
4 from 4_george_39.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_39_fea.pkl
4 from 4_george_31.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_31_fea.pkl
3 from 3_george_17.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_17_fea.pkl
1 from 1_george_9.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_9_fea.pkl
6 from 6_jackson_6.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_6_fea.pkl
8 from 8_jackson_10.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_10_fea.pkl
1 from 1_george_13.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_13_fea.pkl
6 from 6_jackson_11.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_11_fea.pkl
0 from 0_yweweler_40.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_40_fea.pkl
0 from 0_yweweler_32.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_32_fea.pkl
2 from 2_george_6.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_6_fea.pkl
7 from 7_lucas_12.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_12_fea.pkl
1 from 1_george_4.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_4_fea.pkl
0 from 0_yweweler_44.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_44_fea.pkl
7 from 7_lucas_14.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_14_fea.pkl
3 from 3_george_28.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_28_fea.pkl
8 from 8_george_36.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_36_fea.pkl
7 from 7_lucas_20.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_20_fea.pkl
5 from 5_george_36.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_36_fea.pkl
4 from 4_george_42.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_42_fea.pkl
7 from 7_jackson_49.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_jackson_49_fea.pkl
2 from 2_george_14.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_14_fea.pkl
9 from 9_jackson_25.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_25_fea.pkl
7 from 7_lucas_13.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_13_fea.pkl
7 from 7_lucas_9.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_9_fea.pkl
7 from 7_lucas_5.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_5_fea.pkl
8 from 8_george_41.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_41_fea.pkl
8 from 8_jackson_12.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_12_fea.pkl
6 from 6_jackson_8.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_8_fea.pkl
7 from 7_lucas_24.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_24_fea.pkl
0 from 0_yweweler_30.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_30_fea.pkl
4 from 4_george_41.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_41_fea.pkl
7 from 7_lucas_15.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_15_fea.pkl
9 from 9_jackson_33.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_33_fea.pkl
8 from 8_jackson_9.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_9_fea.pkl
5 from 5_george_39.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_39_fea.pkl
0 from 0_yweweler_45.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_45_fea.pkl
5 from 5_george_41.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_41_fea.pkl
8 from 8_george_35.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_35_fea.pkl
8 from 8_jackson_6.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_6_fea.pkl
2 from 2_george_4.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_4_fea.pkl
9 from 9_jackson_27.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_27_fea.pkl
2 from 2_george_12.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_12_fea.pkl
7 from 7_lucas_21.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_21_fea.pkl
6 from 6_jackson_12.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_12_fea.pkl
8 from 8_jackson_19.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_19_fea.pkl
2 from 2_george_13.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_13_fea.pkl
1 from 1_george_11.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_11_fea.pkl
5 from 5_george_46.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_46_fea.pkl
9 from 9_jackson_38.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_38_fea.pkl
3 from 3_george_19.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_19_fea.pkl
2 from 2_george_9.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_9_fea.pkl
0 from 0_yweweler_41.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_41_fea.pkl
5 from 5_jackson_1.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_1_fea.pkl
2 from 2_george_1.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_1_fea.pkl
1 from 1_george_3.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_3_fea.pkl
9 from 9_jackson_29.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_29_fea.pkl
7 from 7_lucas_2.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_2_fea.pkl
9 from 9_jackson_41.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_41_fea.pkl
9 from 9_jackson_40.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_40_fea.pkl
3 from 3_george_21.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_21_fea.pkl
5 from 5_george_40.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_40_fea.pkl
5 from 5_jackson_3.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_3_fea.pkl
7 from 7_lucas_7.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_7_fea.pkl
5 from 5_jackson_7.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_7_fea.pkl
1 from 1_george_6.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_6_fea.pkl
4 from 4_george_26.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_26_fea.pkl
3 from 3_george_12.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_12_fea.pkl
7 from 7_lucas_18.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_18_fea.pkl
3 from 3_george_27.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_27_fea.pkl
0 from 0_yweweler_37.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_37_fea.pkl
3 from 3_george_13.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_13_fea.pkl
6 from 6_george_49.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_george_49_fea.pkl
4 from 4_george_33.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_33_fea.pkl
4 from 4_george_37.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_37_fea.pkl
6 from 6_jackson_1.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_1_fea.pkl
6 from 6_jackson_13.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_13_fea.pkl
8 from 8_george_45.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_45_fea.pkl
8 from 8_george_33.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_33_fea.pkl
2 from 2_george_17.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_17_fea.pkl
7 from 7_lucas_22.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_22_fea.pkl
1 from 1_george_8.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_8_fea.pkl
9 from 9_jackson_30.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_30_fea.pkl
8 from 8_jackson_3.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_3_fea.pkl
8 from 8_jackson_7.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_7_fea.pkl
3 from 3_george_24.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_24_fea.pkl
2 from 2_george_8.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_8_fea.pkl
5 from 5_jackson_8.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_8_fea.pkl
2 from 2_george_15.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_15_fea.pkl
5 from 5_george_42.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_42_fea.pkl
8 from 8_jackson_13.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_13_fea.pkl
9 from 9_jackson_23.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_23_fea.pkl
3 from 3_george_30.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_30_fea.pkl
7 from 7_lucas_19.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_19_fea.pkl
8 from 8_jackson_0.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_0_fea.pkl
3 from 3_george_29.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_29_fea.pkl
0 from 0_yweweler_49.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_49_fea.pkl
5 from 5_george_49.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_49_fea.pkl
8 from 8_jackson_15.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_15_fea.pkl
4 from 4_george_24.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_24_fea.pkl
4 from 4_george_40.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_40_fea.pkl
3 from 3_george_14.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_14_fea.pkl
5 from 5_george_37.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_37_fea.pkl
0 from 0_yweweler_47.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_47_fea.pkl
8 from 8_jackson_18.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_18_fea.pkl
9 from 9_jackson_36.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_36_fea.pkl
0 from 0_yweweler_38.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_38_fea.pkl
7 from 7_lucas_16.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_16_fea.pkl
1 from 1_george_12.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_12_fea.pkl
5 from 5_george_45.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_45_fea.pkl
5 from 5_jackson_6.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_6_fea.pkl
9 from 9_jackson_35.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_35_fea.pkl
4 from 4_george_35.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_35_fea.pkl
0 from 0_yweweler_39.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_39_fea.pkl
8 from 8_jackson_2.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_2_fea.pkl
8 from 8_jackson_17.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_17_fea.pkl
2 from 2_george_2.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_2_fea.pkl
6 from 6_jackson_9.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_9_fea.pkl
3 from 3_george_26.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_26_fea.pkl
2 from 2_george_7.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_7_fea.pkl
3 from 3_george_31.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_31_fea.pkl
0 from 0_yweweler_34.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_34_fea.pkl
4 from 4_george_36.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_36_fea.pkl
0 from 0_yweweler_43.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_43_fea.pkl
8 from 8_george_43.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_43_fea.pkl
6 from 6_jackson_10.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_10_fea.pkl
3 from 3_george_18.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_18_fea.pkl
7 from 7_lucas_6.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_6_fea.pkl
8 from 8_george_44.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_44_fea.pkl
0 from 0_yweweler_35.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_35_fea.pkl
2 from 2_george_16.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_16_fea.pkl
9 from 9_jackson_32.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_32_fea.pkl
5 from 5_jackson_4.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_4_fea.pkl
1 from 1_george_1.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_1_fea.pkl
8 from 8_george_37.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_37_fea.pkl
4 from 4_george_34.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_34_fea.pkl
9 from 9_jackson_37.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_37_fea.pkl
8 from 8_george_34.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_34_fea.pkl
1 from 1_george_2.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_2_fea.pkl
0 from 0_yweweler_36.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_36_fea.pkl
4 from 4_george_27.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_27_fea.pkl
8 from 8_jackson_20.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_20_fea.pkl
7 from 7_lucas_11.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_11_fea.pkl
8 from 8_george_48.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_48_fea.pkl
7 from 7_lucas_4.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_4_fea.pkl
7 from 7_lucas_0.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_0_fea.pkl
9 from 9_jackson_22.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_22_fea.pkl
7 from 7_lucas_1.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_1_fea.pkl
1 from 1_george_7.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_7_fea.pkl
9 from 9_jackson_39.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_39_fea.pkl
1 from 1_george_0.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_0_fea.pkl
4 from 4_george_28.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_28_fea.pkl
5 from 5_george_48.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_48_fea.pkl
8 from 8_jackson_14.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_14_fea.pkl
6 from 6_jackson_0.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_0_fea.pkl
7 from 7_lucas_23.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_23_fea.pkl
4 from 4_george_38.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_38_fea.pkl
8 from 8_jackson_16.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_16_fea.pkl
1 from 1_george_10.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_10_fea.pkl
8 from 8_jackson_1.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_1_fea.pkl
8 from 8_george_39.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_39_fea.pkl
8 from 8_george_46.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_46_fea.pkl
3 from 3_george_22.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_22_fea.pkl
3 from 3_george_23.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_23_fea.pkl
5 from 5_george_47.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_47_fea.pkl
8 from 8_george_42.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_42_fea.pkl
0 from 0_yweweler_42.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_42_fea.pkl
9 from 9_jackson_26.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_26_fea.pkl
1 from 1_george_14.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_14_fea.pkl
0 from 0_yweweler_46.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_46_fea.pkl
8 from 8_jackson_5.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_5_fea.pkl
2 from 2_george_10.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_10_fea.pkl
7 from 7_lucas_8.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_8_fea.pkl
5 from 5_george_38.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_38_fea.pkl
7 from 7_lucas_17.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_17_fea.pkl
9 from 9_jackson_34.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_34_fea.pkl
2 from 2_george_11.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_11_fea.pkl
6 from 6_george_48.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_george_48_fea.pkl
3 from 3_george_20.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_20_fea.pkl
6 from 6_jackson_4.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_4_fea.pkl
2 from 2_george_5.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_5_fea.pkl
8 from 8_jackson_11.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_11_fea.pkl
7 from 7_lucas_3.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/7_lucas_3_fea.pkl
8 from 8_jackson_8.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_8_fea.pkl
2 from 2_george_0.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_0_fea.pkl
0 from 0_yweweler_31.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_31_fea.pkl
4 from 4_george_30.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_30_fea.pkl
3 from 3_george_25.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_25_fea.pkl
5 from 5_george_43.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_george_43_fea.pkl
6 from 6_jackson_7.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_7_fea.pkl
4 from 4_george_32.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_32_fea.pkl
2 from 2_george_3.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/2_george_3_fea.pkl
0 from 0_yweweler_33.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_33_fea.pkl
8 from 8_george_38.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_38_fea.pkl
1 from 1_george_15.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/1_george_15_fea.pkl
8 from 8_george_40.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_40_fea.pkl
0 from 0_yweweler_48.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/0_yweweler_48_fea.pkl
4 from 4_george_29.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_29_fea.pkl
4 from 4_george_25.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/4_george_25_fea.pkl
3 from 3_george_15.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/3_george_15_fea.pkl
5 from 5_jackson_5.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_5_fea.pkl
5 from 5_jackson_0.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_0_fea.pkl
5 from 5_jackson_9.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_9_fea.pkl
6 from 6_jackson_5.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_5_fea.pkl
8 from 8_jackson_4.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_jackson_4_fea.pkl
8 from 8_george_49.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/8_george_49_fea.pkl
9 from 9_jackson_31.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_31_fea.pkl
6 from 6_jackson_15.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/6_jackson_15_fea.pkl
5 from 5_jackson_2.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/5_jackson_2_fea.pkl
9 from 9_jackson_28.wav converted to ../outputs/1melD18T30/features_melD18T30/features_no_resizing/9_jackson_28_fea.pkl
Wrote file ../outputs/1melD18T30/features_melD18T30.hdf5
Considering original features
Frequency dimension range =  18 18
Time dimension range =  16 97
=====================================
Simplified WDP DS Pipeline
Original code by Daniel Kyu Hwa Kohlsdorf
Created output folder ../outputs/1melD18T30/features_melD18T30/encoder_models
Saved file ../outputs/1melD18T30/features_melD18T30/encoder_models/fixed_enc_commandline_args.txt
WARNING!!!! num_examples= 220
<_io.TextIOWrapper name='../general/labels_dictionary.json' mode='r' encoding='UTF-8'>
labels_dict {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}
labels_dict <class 'dict'>
Wrote ../outputs/1melD18T30/features_melD18T30/encoder_models/test_indices.csv
######### General info #########
Fraction reserved for testing: 0.2
label_dict= {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}
by_label keys dict_keys([3, 8, 4, 9, 6, 5, 7, 1, 0, 2])
Histogram:
[(3, 16), (8, 31), (4, 15), (9, 15), (6, 12), (5, 20), (7, 22), (1, 13), (0, 16), (2, 16)]
######### Training the 3 networks #########
Model base_encoder.summary
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, None, 18, 1  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, None, 18, 32  2080        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 conv2d_1 (Conv2D)              (None, None, 18, 32  2080        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 conv2d_2 (Conv2D)              (None, None, 18, 32  2080        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 conv2d_3 (Conv2D)              (None, None, 18, 32  2080        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 conv2d_4 (Conv2D)              (None, None, 18, 32  1056        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 conv2d_5 (Conv2D)              (None, None, 18, 32  2080        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 conv2d_6 (Conv2D)              (None, None, 18, 32  4128        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, None, 1, 32)  0           ['conv2d[0][0]']                 
                                                                                                  
 max_pooling2d_1 (MaxPooling2D)  (None, None, 1, 32)  0          ['conv2d_1[0][0]']               
                                                                                                  
 max_pooling2d_2 (MaxPooling2D)  (None, None, 1, 32)  0          ['conv2d_2[0][0]']               
                                                                                                  
 max_pooling2d_3 (MaxPooling2D)  (None, None, 1, 32)  0          ['conv2d_3[0][0]']               
                                                                                                  
 max_pooling2d_4 (MaxPooling2D)  (None, None, 1, 32)  0          ['conv2d_4[0][0]']               
                                                                                                  
 max_pooling2d_5 (MaxPooling2D)  (None, None, 1, 32)  0          ['conv2d_5[0][0]']               
                                                                                                  
 max_pooling2d_6 (MaxPooling2D)  (None, None, 1, 32)  0          ['conv2d_6[0][0]']               
                                                                                                  
 reshape (Reshape)              (None, None, 32)     0           ['max_pooling2d[0][0]']          
                                                                                                  
 reshape_1 (Reshape)            (None, None, 32)     0           ['max_pooling2d_1[0][0]']        
                                                                                                  
 reshape_2 (Reshape)            (None, None, 32)     0           ['max_pooling2d_2[0][0]']        
                                                                                                  
 reshape_3 (Reshape)            (None, None, 32)     0           ['max_pooling2d_3[0][0]']        
                                                                                                  
 reshape_4 (Reshape)            (None, None, 32)     0           ['max_pooling2d_4[0][0]']        
                                                                                                  
 reshape_5 (Reshape)            (None, None, 32)     0           ['max_pooling2d_5[0][0]']        
                                                                                                  
 reshape_6 (Reshape)            (None, None, 32)     0           ['max_pooling2d_6[0][0]']        
                                                                                                  
 concatenate (Concatenate)      (None, None, 224)    0           ['reshape[0][0]',                
                                                                  'reshape_1[0][0]',              
                                                                  'reshape_2[0][0]',              
                                                                  'reshape_3[0][0]',              
                                                                  'reshape_4[0][0]',              
                                                                  'reshape_5[0][0]',              
                                                                  'reshape_6[0][0]']              
                                                                                                  
 bidirectional (Bidirectional)  (None, None, 6)      5472        ['concatenate[0][0]']            
                                                                                                  
==================================================================================================
Total params: 21,056
Trainable params: 21,056
Non-trainable params: 0
__________________________________________________________________________________________________
Model enc.summary
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 30, 18, 1)]       0         
                                                                 
 model (Functional)          (None, None, 6)           21056     
                                                                 
 lstm_1 (LSTM)               (None, 3)                 120       
                                                                 
=================================================================
Total params: 21,176
Trainable params: 21,176
Non-trainable params: 0
_________________________________________________________________
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_3 (InputLayer)           [(None, 3)]          0           []                               
                                                                                                  
 reshape_7 (Reshape)            (None, 1, 3)         0           ['input_3[0][0]']                
                                                                                                  
 zero_padding1d (ZeroPadding1D)  (None, 30, 3)       0           ['reshape_7[0][0]']              
                                                                                                  
 lstm_2 (LSTM)                  (None, 30, 3)        84          ['zero_padding1d[0][0]']         
                                                                                                  
 bidirectional_1 (Bidirectional  (None, 30, 18)      936         ['lstm_2[0][0]']                 
 )                                                                                                
                                                                                                  
 reshape_8 (Reshape)            (None, 30, 18, 1)    0           ['bidirectional_1[0][0]']        
                                                                                                  
 conv2d_transpose (Conv2DTransp  (None, 30, 18, 32)  2080        ['reshape_8[0][0]']              
 ose)                                                                                             
                                                                                                  
 conv2d_transpose_1 (Conv2DTran  (None, 30, 18, 32)  2080        ['reshape_8[0][0]']              
 spose)                                                                                           
                                                                                                  
 conv2d_transpose_2 (Conv2DTran  (None, 30, 18, 32)  2080        ['reshape_8[0][0]']              
 spose)                                                                                           
                                                                                                  
 conv2d_transpose_3 (Conv2DTran  (None, 30, 18, 32)  2080        ['reshape_8[0][0]']              
 spose)                                                                                           
                                                                                                  
 conv2d_transpose_4 (Conv2DTran  (None, 30, 18, 32)  1056        ['reshape_8[0][0]']              
 spose)                                                                                           
                                                                                                  
 conv2d_transpose_5 (Conv2DTran  (None, 30, 18, 32)  2080        ['reshape_8[0][0]']              
 spose)                                                                                           
                                                                                                  
 conv2d_transpose_6 (Conv2DTran  (None, 30, 18, 32)  4128        ['reshape_8[0][0]']              
 spose)                                                                                           
                                                                                                  
 concatenate_1 (Concatenate)    (None, 30, 18, 224)  0           ['conv2d_transpose[0][0]',       
                                                                  'conv2d_transpose_1[0][0]',     
                                                                  'conv2d_transpose_2[0][0]',     
                                                                  'conv2d_transpose_3[0][0]',     
                                                                  'conv2d_transpose_4[0][0]',     
                                                                  'conv2d_transpose_5[0][0]',     
                                                                  'conv2d_transpose_6[0][0]']     
                                                                                                  
 conv2d_transpose_7 (Conv2DTran  (None, 30, 18, 1)   225         ['concatenate_1[0][0]']          
 spose)                                                                                           
                                                                                                  
==================================================================================================
Total params: 16,829
Trainable params: 16,829
Non-trainable params: 0
__________________________________________________________________________________________________
(auto_encoder) ae.summary
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 30, 18, 1)]       0         
                                                                 
 model_1 (Functional)        (None, 3)                 21176     
                                                                 
 model_2 (Functional)        (None, 30, 18, 1)         16829     
                                                                 
=================================================================
Total params: 38,005
Trainable params: 38,005
Non-trainable params: 0
_________________________________________________________________
######### Super epoch =  1 / 2 #########
######### Improving encoder via triplet loss #########
Siamese network model
Model: "model_5"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_6 (InputLayer)           [(None, 30, 18, 1)]  0           []                               
                                                                                                  
 input_7 (InputLayer)           [(None, 30, 18, 1)]  0           []                               
                                                                                                  
 input_8 (InputLayer)           [(None, 30, 18, 1)]  0           []                               
                                                                                                  
 model_4 (Functional)           (None, 3)            21176       ['input_6[0][0]',                
                                                                  'input_7[0][0]',                
                                                                  'input_8[0][0]']                
                                                                                                  
 concatenate_2 (Concatenate)    (None, 9)            0           ['model_4[0][0]',                
                                                                  'model_4[1][0]',                
                                                                  'model_4[2][0]']                
                                                                                                  
==================================================================================================
Total params: 21,176
Trainable params: 21,176
Non-trainable params: 0
__________________________________________________________________________________________________
None
EPOCH: 1 / 10 n=10 / 300 LOSS for last ten n values: 30.519407510757446
EPOCH: 1 / 10 n=20 / 300 LOSS for last ten n values: 29.973074436187744
EPOCH: 1 / 10 n=30 / 300 LOSS for last ten n values: 29.991140842437744
EPOCH: 1 / 10 n=40 / 300 LOSS for last ten n values: 29.995463609695435
EPOCH: 1 / 10 n=50 / 300 LOSS for last ten n values: 29.981122255325317
EPOCH: 1 / 10 n=60 / 300 LOSS for last ten n values: 29.996077299118042
EPOCH: 1 / 10 n=70 / 300 LOSS for last ten n values: 29.98205876350403
EPOCH: 1 / 10 n=80 / 300 LOSS for last ten n values: 29.99624228477478
EPOCH: 1 / 10 n=90 / 300 LOSS for last ten n values: 29.988856554031372
EPOCH: 1 / 10 n=100 / 300 LOSS for last ten n values: 29.970500707626343
EPOCH: 2 / 10 n=10 / 300 LOSS for last ten n values: 29.972171783447266
EPOCH: 2 / 10 n=20 / 300 LOSS for last ten n values: 29.931479454040527
EPOCH: 2 / 10 n=30 / 300 LOSS for last ten n values: 29.909029006958008
EPOCH: 2 / 10 n=40 / 300 LOSS for last ten n values: 29.931879997253418
EPOCH: 2 / 10 n=50 / 300 LOSS for last ten n values: 29.742974519729614
EPOCH: 2 / 10 n=60 / 300 LOSS for last ten n values: 27.81941246986389
EPOCH: 2 / 10 n=70 / 300 LOSS for last ten n values: 26.60719132423401
EPOCH: 2 / 10 n=80 / 300 LOSS for last ten n values: 29.951525688171387
EPOCH: 2 / 10 n=90 / 300 LOSS for last ten n values: 29.95154333114624
EPOCH: 2 / 10 n=100 / 300 LOSS for last ten n values: 29.95846724510193
EPOCH: 3 / 10 n=10 / 300 LOSS for last ten n values: 29.9356951713562
EPOCH: 3 / 10 n=20 / 300 LOSS for last ten n values: 29.979706525802612
EPOCH: 3 / 10 n=30 / 300 LOSS for last ten n values: 29.919589042663574
EPOCH: 3 / 10 n=40 / 300 LOSS for last ten n values: 29.814908981323242
EPOCH: 3 / 10 n=50 / 300 LOSS for last ten n values: 29.65268874168396
EPOCH: 3 / 10 n=60 / 300 LOSS for last ten n values: 29.275697946548462
EPOCH: 3 / 10 n=70 / 300 LOSS for last ten n values: 28.65261173248291
EPOCH: 3 / 10 n=80 / 300 LOSS for last ten n values: 26.166107416152954
EPOCH: 3 / 10 n=90 / 300 LOSS for last ten n values: 25.55817997455597
EPOCH: 3 / 10 n=100 / 300 LOSS for last ten n values: 28.88965666294098
EPOCH: 4 / 10 n=10 / 300 LOSS for last ten n values: 29.917977333068848
EPOCH: 4 / 10 n=20 / 300 LOSS for last ten n values: 29.90193796157837
EPOCH: 4 / 10 n=30 / 300 LOSS for last ten n values: 29.877447843551636
EPOCH: 4 / 10 n=40 / 300 LOSS for last ten n values: 29.86266589164734
EPOCH: 4 / 10 n=50 / 300 LOSS for last ten n values: 29.795580625534058
EPOCH: 4 / 10 n=60 / 300 LOSS for last ten n values: 29.462024211883545
EPOCH: 4 / 10 n=70 / 300 LOSS for last ten n values: 29.877233028411865
EPOCH: 4 / 10 n=80 / 300 LOSS for last ten n values: 27.606945753097534
EPOCH: 4 / 10 n=90 / 300 LOSS for last ten n values: 27.278661131858826
EPOCH: 4 / 10 n=100 / 300 LOSS for last ten n values: 27.297158002853394
EPOCH: 5 / 10 n=10 / 300 LOSS for last ten n values: 22.084757030010223
EPOCH: 5 / 10 n=20 / 300 LOSS for last ten n values: 20.809779226779938
EPOCH: 5 / 10 n=30 / 300 LOSS for last ten n values: 14.804017722606659
EPOCH: 5 / 10 n=40 / 300 LOSS for last ten n values: 19.551775813102722
EPOCH: 5 / 10 n=50 / 300 LOSS for last ten n values: 22.42952623963356
EPOCH: 5 / 10 n=60 / 300 LOSS for last ten n values: 20.98554003238678
EPOCH: 5 / 10 n=70 / 300 LOSS for last ten n values: 23.587870061397552
EPOCH: 5 / 10 n=80 / 300 LOSS for last ten n values: 17.827717006206512
EPOCH: 5 / 10 n=90 / 300 LOSS for last ten n values: 14.097980976104736
EPOCH: 5 / 10 n=100 / 300 LOSS for last ten n values: 19.725588500499725
EPOCH: 6 / 10 n=10 / 300 LOSS for last ten n values: 15.093900114297867
EPOCH: 6 / 10 n=20 / 300 LOSS for last ten n values: 21.10390841960907
EPOCH: 6 / 10 n=30 / 300 LOSS for last ten n values: 10.217592403292656
EPOCH: 6 / 10 n=40 / 300 LOSS for last ten n values: 15.207260549068451
EPOCH: 6 / 10 n=50 / 300 LOSS for last ten n values: 27.377447843551636
EPOCH: 6 / 10 n=60 / 300 LOSS for last ten n values: 15.025978207588196
EPOCH: 6 / 10 n=70 / 300 LOSS for last ten n values: 13.892180114984512
EPOCH: 6 / 10 n=80 / 300 LOSS for last ten n values: 18.048991084098816
EPOCH: 6 / 10 n=90 / 300 LOSS for last ten n values: 18.497870564460754
EPOCH: 6 / 10 n=100 / 300 LOSS for last ten n values: 13.631660997867584
EPOCH: 7 / 10 n=10 / 300 LOSS for last ten n values: 18.4289610683918
EPOCH: 7 / 10 n=20 / 300 LOSS for last ten n values: 12.81320033967495
EPOCH: 7 / 10 n=30 / 300 LOSS for last ten n values: 9.050593197345734
EPOCH: 7 / 10 n=40 / 300 LOSS for last ten n values: 12.804561018943787
EPOCH: 7 / 10 n=50 / 300 LOSS for last ten n values: 20.839980334043503
EPOCH: 7 / 10 n=60 / 300 LOSS for last ten n values: 23.166627287864685
EPOCH: 7 / 10 n=70 / 300 LOSS for last ten n values: 22.235392831265926
EPOCH: 7 / 10 n=80 / 300 LOSS for last ten n values: 30.380273818969727
EPOCH: 7 / 10 n=90 / 300 LOSS for last ten n values: 21.18828445672989
EPOCH: 7 / 10 n=100 / 300 LOSS for last ten n values: 22.815501987934113
EPOCH: 8 / 10 n=10 / 300 LOSS for last ten n values: 22.242292821407318
EPOCH: 8 / 10 n=20 / 300 LOSS for last ten n values: 26.38665461540222
EPOCH: 8 / 10 n=30 / 300 LOSS for last ten n values: 18.43173187971115
EPOCH: 8 / 10 n=40 / 300 LOSS for last ten n values: 26.8819717168808
EPOCH: 8 / 10 n=50 / 300 LOSS for last ten n values: 25.77319312095642
EPOCH: 8 / 10 n=60 / 300 LOSS for last ten n values: 26.435624718666077
EPOCH: 8 / 10 n=70 / 300 LOSS for last ten n values: 17.425289511680603
EPOCH: 8 / 10 n=80 / 300 LOSS for last ten n values: 18.857987642288208
EPOCH: 8 / 10 n=90 / 300 LOSS for last ten n values: 25.56922209262848
EPOCH: 8 / 10 n=100 / 300 LOSS for last ten n values: 23.363074630498886
EPOCH: 9 / 10 n=10 / 300 LOSS for last ten n values: 25.15514063835144
EPOCH: 9 / 10 n=20 / 300 LOSS for last ten n values: 20.157981276512146
EPOCH: 9 / 10 n=30 / 300 LOSS for last ten n values: 10.485072195529938
EPOCH: 9 / 10 n=40 / 300 LOSS for last ten n values: 14.014604687690735
EPOCH: 9 / 10 n=50 / 300 LOSS for last ten n values: 23.30356828868389
EPOCH: 9 / 10 n=60 / 300 LOSS for last ten n values: 10.540391325950623
EPOCH: 9 / 10 n=70 / 300 LOSS for last ten n values: 16.456689417362213
EPOCH: 9 / 10 n=80 / 300 LOSS for last ten n values: 22.66371351480484
EPOCH: 9 / 10 n=90 / 300 LOSS for last ten n values: 18.713271260261536
EPOCH: 9 / 10 n=100 / 300 LOSS for last ten n values: 12.014340534806252
EPOCH: 10 / 10 n=10 / 300 LOSS for last ten n values: 20.105429589748383
EPOCH: 10 / 10 n=20 / 300 LOSS for last ten n values: 15.009882032871246
EPOCH: 10 / 10 n=30 / 300 LOSS for last ten n values: 15.818000614643097
EPOCH: 10 / 10 n=40 / 300 LOSS for last ten n values: 19.139240264892578
EPOCH: 10 / 10 n=50 / 300 LOSS for last ten n values: 15.874186366796494
EPOCH: 10 / 10 n=60 / 300 LOSS for last ten n values: 12.047358274459839
EPOCH: 10 / 10 n=70 / 300 LOSS for last ten n values: 16.384790301322937
EPOCH: 10 / 10 n=80 / 300 LOSS for last ten n values: 13.47486886382103
EPOCH: 10 / 10 n=90 / 300 LOSS for last ten n values: 12.493933975696564
EPOCH: 10 / 10 n=100 / 300 LOSS for last ten n values: 5.60010002553463
######### Saving current networks and filters based on triplet loss training #########
######### Train classifier based on encoder output (and improve base_encoder and encoder) #########
Model (classifier).summary()
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 30, 18, 1)]       0         
                                                                 
 model_1 (Functional)        (None, 3)                 21176     
                                                                 
 dropout (Dropout)           (None, 3)                 0         
                                                                 
 dense (Dense)               (None, 10)                40        
                                                                 
=================================================================
Total params: 21,216
Trainable params: 21,216
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
 1/46 [..............................] - ETA: 3:11 - loss: 2.4551 - accuracy: 0.0000e+00 6/46 [==>...........................] - ETA: 0s - loss: 2.3516 - accuracy: 0.0000e+00  11/46 [======>.......................] - ETA: 0s - loss: 2.3422 - accuracy: 0.0000e+0015/46 [========>.....................] - ETA: 0s - loss: 2.3211 - accuracy: 0.0222    20/46 [============>.................] - ETA: 0s - loss: 2.3149 - accuracy: 0.050025/46 [===============>..............] - ETA: 0s - loss: 2.3127 - accuracy: 0.053330/46 [==================>...........] - ETA: 0s - loss: 2.3028 - accuracy: 0.077835/46 [=====================>........] - ETA: 0s - loss: 2.2986 - accuracy: 0.076240/46 [=========================>....] - ETA: 0s - loss: 2.2989 - accuracy: 0.075045/46 [============================>.] - ETA: 0s - loss: 2.2983 - accuracy: 0.066746/46 [==============================] - 6s 33ms/step - loss: 2.3000 - accuracy: 0.0652 - val_loss: 2.3002 - val_accuracy: 0.0833
Epoch 2/10
 1/46 [..............................] - ETA: 0s - loss: 2.3206 - accuracy: 0.0000e+00 6/46 [==>...........................] - ETA: 0s - loss: 2.2822 - accuracy: 0.1667    11/46 [======>.......................] - ETA: 0s - loss: 2.3023 - accuracy: 0.121215/46 [========>.....................] - ETA: 0s - loss: 2.2901 - accuracy: 0.111120/46 [============>.................] - ETA: 0s - loss: 2.2828 - accuracy: 0.133325/46 [===============>..............] - ETA: 0s - loss: 2.2784 - accuracy: 0.133330/46 [==================>...........] - ETA: 0s - loss: 2.2838 - accuracy: 0.133335/46 [=====================>........] - ETA: 0s - loss: 2.2815 - accuracy: 0.133338/46 [=======================>......] - ETA: 0s - loss: 2.2817 - accuracy: 0.122840/46 [=========================>....] - ETA: 0s - loss: 2.2750 - accuracy: 0.133342/46 [==========================>...] - ETA: 0s - loss: 2.2732 - accuracy: 0.142943/46 [===========================>..] - ETA: 0s - loss: 2.2787 - accuracy: 0.139545/46 [============================>.] - ETA: 0s - loss: 2.2820 - accuracy: 0.133346/46 [==============================] - 1s 23ms/step - loss: 2.2819 - accuracy: 0.1377 - val_loss: 2.2960 - val_accuracy: 0.0833
Epoch 3/10
 1/46 [..............................] - ETA: 1s - loss: 2.3971 - accuracy: 0.0000e+00 4/46 [=>............................] - ETA: 0s - loss: 2.3816 - accuracy: 0.0000e+00 7/46 [===>..........................] - ETA: 0s - loss: 2.3661 - accuracy: 0.1429    10/46 [=====>........................] - ETA: 0s - loss: 2.3427 - accuracy: 0.100013/46 [=======>......................] - ETA: 0s - loss: 2.3201 - accuracy: 0.128216/46 [=========>....................] - ETA: 0s - loss: 2.3153 - accuracy: 0.145819/46 [===========>..................] - ETA: 0s - loss: 2.3143 - accuracy: 0.140422/46 [=============>................] - ETA: 0s - loss: 2.3267 - accuracy: 0.151525/46 [===============>..............] - ETA: 0s - loss: 2.3292 - accuracy: 0.146728/46 [=================>............] - ETA: 0s - loss: 2.3344 - accuracy: 0.131031/46 [===================>..........] - ETA: 0s - loss: 2.3323 - accuracy: 0.118334/46 [=====================>........] - ETA: 0s - loss: 2.3282 - accuracy: 0.107837/46 [=======================>......] - ETA: 0s - loss: 2.3303 - accuracy: 0.099140/46 [=========================>....] - ETA: 0s - loss: 2.3260 - accuracy: 0.100043/46 [===========================>..] - ETA: 0s - loss: 2.3238 - accuracy: 0.093046/46 [==============================] - ETA: 0s - loss: 2.3175 - accuracy: 0.101446/46 [==============================] - 1s 22ms/step - loss: 2.3175 - accuracy: 0.1014 - val_loss: 2.2920 - val_accuracy: 0.0833
Epoch 4/10
 1/46 [..............................] - ETA: 1s - loss: 2.2376 - accuracy: 0.3333 4/46 [=>............................] - ETA: 0s - loss: 2.3021 - accuracy: 0.0833 7/46 [===>..........................] - ETA: 0s - loss: 2.3136 - accuracy: 0.095210/46 [=====>........................] - ETA: 0s - loss: 2.3024 - accuracy: 0.066713/46 [=======>......................] - ETA: 0s - loss: 2.3036 - accuracy: 0.051316/46 [=========>....................] - ETA: 0s - loss: 2.3003 - accuracy: 0.062519/46 [===========>..................] - ETA: 0s - loss: 2.2887 - accuracy: 0.070222/46 [=============>................] - ETA: 0s - loss: 2.2943 - accuracy: 0.060625/46 [===============>..............] - ETA: 0s - loss: 2.2913 - accuracy: 0.106728/46 [=================>............] - ETA: 0s - loss: 2.2934 - accuracy: 0.107131/46 [===================>..........] - ETA: 0s - loss: 2.2915 - accuracy: 0.096834/46 [=====================>........] - ETA: 0s - loss: 2.2946 - accuracy: 0.098037/46 [=======================>......] - ETA: 0s - loss: 2.2877 - accuracy: 0.117140/46 [=========================>....] - ETA: 0s - loss: 2.2937 - accuracy: 0.108343/46 [===========================>..] - ETA: 0s - loss: 2.3018 - accuracy: 0.100846/46 [==============================] - ETA: 0s - loss: 2.2950 - accuracy: 0.115946/46 [==============================] - 1s 23ms/step - loss: 2.2950 - accuracy: 0.1159 - val_loss: 2.2885 - val_accuracy: 0.1667
Epoch 5/10
 1/46 [..............................] - ETA: 0s - loss: 2.4560 - accuracy: 0.0000e+00 6/46 [==>...........................] - ETA: 0s - loss: 2.3299 - accuracy: 0.1111    11/46 [======>.......................] - ETA: 0s - loss: 2.3140 - accuracy: 0.151516/46 [=========>....................] - ETA: 0s - loss: 2.3280 - accuracy: 0.145821/46 [============>.................] - ETA: 0s - loss: 2.3264 - accuracy: 0.127026/46 [===============>..............] - ETA: 0s - loss: 2.3056 - accuracy: 0.166731/46 [===================>..........] - ETA: 0s - loss: 2.3096 - accuracy: 0.172036/46 [======================>.......] - ETA: 0s - loss: 2.3021 - accuracy: 0.175940/46 [=========================>....] - ETA: 0s - loss: 2.2970 - accuracy: 0.166745/46 [============================>.] - ETA: 0s - loss: 2.2919 - accuracy: 0.170446/46 [==============================] - 1s 13ms/step - loss: 2.2961 - accuracy: 0.1667 - val_loss: 2.2851 - val_accuracy: 0.1667
Epoch 6/10
 1/46 [..............................] - ETA: 0s - loss: 2.2856 - accuracy: 0.0000e+00 6/46 [==>...........................] - ETA: 0s - loss: 2.3045 - accuracy: 0.0556    11/46 [======>.......................] - ETA: 0s - loss: 2.2971 - accuracy: 0.121216/46 [=========>....................] - ETA: 0s - loss: 2.2963 - accuracy: 0.145821/46 [============>.................] - ETA: 0s - loss: 2.2980 - accuracy: 0.127025/46 [===============>..............] - ETA: 0s - loss: 2.2834 - accuracy: 0.173329/46 [=================>............] - ETA: 0s - loss: 2.2768 - accuracy: 0.160934/46 [=====================>........] - ETA: 0s - loss: 2.2736 - accuracy: 0.176538/46 [=======================>......] - ETA: 0s - loss: 2.2764 - accuracy: 0.184243/46 [===========================>..] - ETA: 0s - loss: 2.2817 - accuracy: 0.170546/46 [==============================] - 1s 14ms/step - loss: 2.2809 - accuracy: 0.1667 - val_loss: 2.2829 - val_accuracy: 0.1667
Epoch 7/10
 1/46 [..............................] - ETA: 0s - loss: 2.3194 - accuracy: 0.0000e+00 6/46 [==>...........................] - ETA: 0s - loss: 2.2948 - accuracy: 0.0556    11/46 [======>.......................] - ETA: 0s - loss: 2.3020 - accuracy: 0.121216/46 [=========>....................] - ETA: 0s - loss: 2.2877 - accuracy: 0.125020/46 [============>.................] - ETA: 0s - loss: 2.2861 - accuracy: 0.133324/46 [==============>...............] - ETA: 0s - loss: 2.2811 - accuracy: 0.125029/46 [=================>............] - ETA: 0s - loss: 2.2809 - accuracy: 0.126434/46 [=====================>........] - ETA: 0s - loss: 2.2833 - accuracy: 0.127539/46 [========================>.....] - ETA: 0s - loss: 2.2769 - accuracy: 0.145343/46 [===========================>..] - ETA: 0s - loss: 2.2765 - accuracy: 0.147346/46 [==============================] - 1s 14ms/step - loss: 2.2773 - accuracy: 0.1449 - val_loss: 2.2708 - val_accuracy: 0.1667
Epoch 8/10
 1/46 [..............................] - ETA: 0s - loss: 2.4726 - accuracy: 0.0000e+00 5/46 [==>...........................] - ETA: 0s - loss: 2.3454 - accuracy: 0.0000e+00 9/46 [====>.........................] - ETA: 0s - loss: 2.3071 - accuracy: 0.0741    14/46 [========>.....................] - ETA: 0s - loss: 2.3088 - accuracy: 0.071419/46 [===========>..................] - ETA: 0s - loss: 2.3019 - accuracy: 0.087724/46 [==============>...............] - ETA: 0s - loss: 2.2975 - accuracy: 0.125029/46 [=================>............] - ETA: 0s - loss: 2.2848 - accuracy: 0.149434/46 [=====================>........] - ETA: 0s - loss: 2.2780 - accuracy: 0.156939/46 [========================>.....] - ETA: 0s - loss: 2.2661 - accuracy: 0.188044/46 [===========================>..] - ETA: 0s - loss: 2.2584 - accuracy: 0.189446/46 [==============================] - 1s 14ms/step - loss: 2.2538 - accuracy: 0.1884 - val_loss: 2.2579 - val_accuracy: 0.1667
Epoch 9/10
 1/46 [..............................] - ETA: 0s - loss: 2.0789 - accuracy: 0.3333 6/46 [==>...........................] - ETA: 0s - loss: 2.2149 - accuracy: 0.333311/46 [======>.......................] - ETA: 0s - loss: 2.2657 - accuracy: 0.212116/46 [=========>....................] - ETA: 0s - loss: 2.2410 - accuracy: 0.250021/46 [============>.................] - ETA: 0s - loss: 2.2435 - accuracy: 0.254026/46 [===============>..............] - ETA: 0s - loss: 2.2671 - accuracy: 0.217931/46 [===================>..........] - ETA: 0s - loss: 2.2690 - accuracy: 0.193535/46 [=====================>........] - ETA: 0s - loss: 2.2631 - accuracy: 0.190540/46 [=========================>....] - ETA: 0s - loss: 2.2521 - accuracy: 0.208345/46 [============================>.] - ETA: 0s - loss: 2.2621 - accuracy: 0.192646/46 [==============================] - 1s 14ms/step - loss: 2.2640 - accuracy: 0.1884 - val_loss: 2.2371 - val_accuracy: 0.1667
Epoch 10/10
 1/46 [..............................] - ETA: 0s - loss: 2.3555 - accuracy: 0.0000e+00 6/46 [==>...........................] - ETA: 0s - loss: 2.2368 - accuracy: 0.2222    11/46 [======>.......................] - ETA: 0s - loss: 2.2624 - accuracy: 0.181816/46 [=========>....................] - ETA: 0s - loss: 2.2594 - accuracy: 0.208321/46 [============>.................] - ETA: 0s - loss: 2.2739 - accuracy: 0.190525/46 [===============>..............] - ETA: 0s - loss: 2.2597 - accuracy: 0.173330/46 [==================>...........] - ETA: 0s - loss: 2.2596 - accuracy: 0.177835/46 [=====================>........] - ETA: 0s - loss: 2.2704 - accuracy: 0.152440/46 [=========================>....] - ETA: 0s - loss: 2.2406 - accuracy: 0.191745/46 [============================>.] - ETA: 0s - loss: 2.2366 - accuracy: 0.185246/46 [==============================] - 1s 14ms/step - loss: 2.2398 - accuracy: 0.1812 - val_loss: 2.2258 - val_accuracy: 0.1667
######### Saving current networks and filters based on classifier trained with supervised learning #########
######### Saving confusion matrix based on classifier trained with supervised learning #########
1/2 [==============>...............] - ETA: 0s2/2 [==============================] - 1s 4ms/step
######### Train autoencoder (and improve base_encoder and encoder) #########
Epoch 1/10
 1/59 [..............................] - ETA: 6:59 - loss: 0.6137 2/59 [>.............................] - ETA: 3s - loss: 0.5788   3/59 [>.............................] - ETA: 4s - loss: 0.5650 4/59 [=>............................] - ETA: 3s - loss: 0.5515 5/59 [=>............................] - ETA: 3s - loss: 0.5518 6/59 [==>...........................] - ETA: 3s - loss: 0.5461 7/59 [==>...........................] - ETA: 3s - loss: 0.5377 8/59 [===>..........................] - ETA: 3s - loss: 0.5284 9/59 [===>..........................] - ETA: 3s - loss: 0.514110/59 [====>.........................] - ETA: 3s - loss: 0.503611/59 [====>.........................] - ETA: 3s - loss: 0.496112/59 [=====>........................] - ETA: 3s - loss: 0.488213/59 [=====>........................] - ETA: 3s - loss: 0.474514/59 [======>.......................] - ETA: 3s - loss: 0.467015/59 [======>.......................] - ETA: 3s - loss: 0.457516/59 [=======>......................] - ETA: 2s - loss: 0.452217/59 [=======>......................] - ETA: 2s - loss: 0.447418/59 [========>.....................] - ETA: 2s - loss: 0.443719/59 [========>.....................] - ETA: 2s - loss: 0.438820/59 [=========>....................] - ETA: 2s - loss: 0.433021/59 [=========>....................] - ETA: 2s - loss: 0.428622/59 [==========>...................] - ETA: 2s - loss: 0.423723/59 [==========>...................] - ETA: 2s - loss: 0.420524/59 [===========>..................] - ETA: 2s - loss: 0.415625/59 [===========>..................] - ETA: 2s - loss: 0.412526/59 [============>.................] - ETA: 2s - loss: 0.405927/59 [============>.................] - ETA: 2s - loss: 0.401228/59 [=============>................] - ETA: 2s - loss: 0.398029/59 [=============>................] - ETA: 2s - loss: 0.394330/59 [==============>...............] - ETA: 2s - loss: 0.393931/59 [==============>...............] - ETA: 2s - loss: 0.390132/59 [===============>..............] - ETA: 2s - loss: 0.385733/59 [===============>..............] - ETA: 1s - loss: 0.382234/59 [================>.............] - ETA: 1s - loss: 0.378035/59 [================>.............] - ETA: 1s - loss: 0.373636/59 [=================>............] - ETA: 1s - loss: 0.370037/59 [=================>............] - ETA: 1s - loss: 0.370238/59 [==================>...........] - ETA: 1s - loss: 0.369439/59 [==================>...........] - ETA: 1s - loss: 0.368540/59 [===================>..........] - ETA: 1s - loss: 0.368041/59 [===================>..........] - ETA: 1s - loss: 0.367142/59 [====================>.........] - ETA: 1s - loss: 0.364643/59 [====================>.........] - ETA: 1s - loss: 0.362344/59 [=====================>........] - ETA: 1s - loss: 0.360545/59 [=====================>........] - ETA: 1s - loss: 0.358546/59 [======================>.......] - ETA: 1s - loss: 0.356847/59 [======================>.......] - ETA: 0s - loss: 0.355248/59 [=======================>......] - ETA: 0s - loss: 0.354449/59 [=======================>......] - ETA: 0s - loss: 0.353450/59 [========================>.....] - ETA: 0s - loss: 0.353451/59 [========================>.....] - ETA: 0s - loss: 0.351852/59 [=========================>....] - ETA: 0s - loss: 0.350953/59 [=========================>....] - ETA: 0s - loss: 0.349254/59 [==========================>...] - ETA: 0s - loss: 0.347655/59 [==========================>...] - ETA: 0s - loss: 0.346056/59 [===========================>..] - ETA: 0s - loss: 0.345357/59 [===========================>..] - ETA: 0s - loss: 0.344958/59 [============================>.] - ETA: 0s - loss: 0.345759/59 [==============================] - 12s 83ms/step - loss: 0.3450
Epoch 2/10
 1/59 [..............................] - ETA: 3s - loss: 0.2662 2/59 [>.............................] - ETA: 3s - loss: 0.2586 3/59 [>.............................] - ETA: 3s - loss: 0.2489 4/59 [=>............................] - ETA: 3s - loss: 0.2498 5/59 [=>............................] - ETA: 3s - loss: 0.2459 6/59 [==>...........................] - ETA: 3s - loss: 0.2435 7/59 [==>...........................] - ETA: 3s - loss: 0.2491 8/59 [===>..........................] - ETA: 3s - loss: 0.2467 9/59 [===>..........................] - ETA: 3s - loss: 0.246310/59 [====>.........................] - ETA: 3s - loss: 0.244911/59 [====>.........................] - ETA: 3s - loss: 0.242412/59 [=====>........................] - ETA: 3s - loss: 0.243713/59 [=====>........................] - ETA: 3s - loss: 0.243314/59 [======>.......................] - ETA: 3s - loss: 0.246415/59 [======>.......................] - ETA: 2s - loss: 0.247816/59 [=======>......................] - ETA: 2s - loss: 0.252117/59 [=======>......................] - ETA: 2s - loss: 0.250618/59 [========>.....................] - ETA: 2s - loss: 0.249019/59 [========>.....................] - ETA: 2s - loss: 0.251220/59 [=========>....................] - ETA: 2s - loss: 0.250921/59 [=========>....................] - ETA: 2s - loss: 0.250222/59 [==========>...................] - ETA: 2s - loss: 0.253523/59 [==========>...................] - ETA: 2s - loss: 0.253224/59 [===========>..................] - ETA: 2s - loss: 0.258025/59 [===========>..................] - ETA: 2s - loss: 0.258526/59 [============>.................] - ETA: 2s - loss: 0.260827/59 [============>.................] - ETA: 2s - loss: 0.260628/59 [=============>................] - ETA: 2s - loss: 0.262029/59 [=============>................] - ETA: 2s - loss: 0.261130/59 [==============>...............] - ETA: 1s - loss: 0.262431/59 [==============>...............] - ETA: 1s - loss: 0.263832/59 [===============>..............] - ETA: 1s - loss: 0.262733/59 [===============>..............] - ETA: 1s - loss: 0.265334/59 [================>.............] - ETA: 1s - loss: 0.265435/59 [================>.............] - ETA: 1s - loss: 0.266236/59 [=================>............] - ETA: 1s - loss: 0.265037/59 [=================>............] - ETA: 1s - loss: 0.266038/59 [==================>...........] - ETA: 1s - loss: 0.266239/59 [==================>...........] - ETA: 1s - loss: 0.267340/59 [===================>..........] - ETA: 1s - loss: 0.269141/59 [===================>..........] - ETA: 1s - loss: 0.269142/59 [====================>.........] - ETA: 1s - loss: 0.270343/59 [====================>.........] - ETA: 1s - loss: 0.269944/59 [=====================>........] - ETA: 1s - loss: 0.269245/59 [=====================>........] - ETA: 0s - loss: 0.268046/59 [======================>.......] - ETA: 0s - loss: 0.270247/59 [======================>.......] - ETA: 0s - loss: 0.270148/59 [=======================>......] - ETA: 0s - loss: 0.269349/59 [=======================>......] - ETA: 0s - loss: 0.269450/59 [========================>.....] - ETA: 0s - loss: 0.269551/59 [========================>.....] - ETA: 0s - loss: 0.268352/59 [=========================>....] - ETA: 0s - loss: 0.267253/59 [=========================>....] - ETA: 0s - loss: 0.265654/59 [==========================>...] - ETA: 0s - loss: 0.266055/59 [==========================>...] - ETA: 0s - loss: 0.265256/59 [===========================>..] - ETA: 0s - loss: 0.265257/59 [===========================>..] - ETA: 0s - loss: 0.265358/59 [============================>.] - ETA: 0s - loss: 0.265759/59 [==============================] - ETA: 0s - loss: 0.265059/59 [==============================] - 4s 67ms/step - loss: 0.2650
Epoch 3/10
 1/59 [..............................] - ETA: 3s - loss: 0.2277 2/59 [>.............................] - ETA: 3s - loss: 0.2090 3/59 [>.............................] - ETA: 3s - loss: 0.1986 4/59 [=>............................] - ETA: 3s - loss: 0.2110 5/59 [=>............................] - ETA: 3s - loss: 0.2209 6/59 [==>...........................] - ETA: 3s - loss: 0.2194 7/59 [==>...........................] - ETA: 3s - loss: 0.2123 8/59 [===>..........................] - ETA: 3s - loss: 0.2201 9/59 [===>..........................] - ETA: 3s - loss: 0.226310/59 [====>.........................] - ETA: 3s - loss: 0.226611/59 [====>.........................] - ETA: 3s - loss: 0.242712/59 [=====>........................] - ETA: 3s - loss: 0.239613/59 [=====>........................] - ETA: 3s - loss: 0.242814/59 [======>.......................] - ETA: 3s - loss: 0.242715/59 [======>.......................] - ETA: 2s - loss: 0.242916/59 [=======>......................] - ETA: 2s - loss: 0.244017/59 [=======>......................] - ETA: 2s - loss: 0.241218/59 [========>.....................] - ETA: 2s - loss: 0.247819/59 [========>.....................] - ETA: 2s - loss: 0.251420/59 [=========>....................] - ETA: 2s - loss: 0.250621/59 [=========>....................] - ETA: 2s - loss: 0.250522/59 [==========>...................] - ETA: 2s - loss: 0.248923/59 [==========>...................] - ETA: 2s - loss: 0.250624/59 [===========>..................] - ETA: 2s - loss: 0.248925/59 [===========>..................] - ETA: 2s - loss: 0.247326/59 [============>.................] - ETA: 2s - loss: 0.245827/59 [============>.................] - ETA: 2s - loss: 0.247828/59 [=============>................] - ETA: 2s - loss: 0.252429/59 [=============>................] - ETA: 2s - loss: 0.251330/59 [==============>...............] - ETA: 1s - loss: 0.250131/59 [==============>...............] - ETA: 1s - loss: 0.250132/59 [===============>..............] - ETA: 1s - loss: 0.250633/59 [===============>..............] - ETA: 1s - loss: 0.250034/59 [================>.............] - ETA: 1s - loss: 0.250535/59 [================>.............] - ETA: 1s - loss: 0.251136/59 [=================>............] - ETA: 1s - loss: 0.250337/59 [=================>............] - ETA: 1s - loss: 0.250638/59 [==================>...........] - ETA: 1s - loss: 0.248839/59 [==================>...........] - ETA: 1s - loss: 0.246940/59 [===================>..........] - ETA: 1s - loss: 0.245641/59 [===================>..........] - ETA: 1s - loss: 0.247642/59 [====================>.........] - ETA: 1s - loss: 0.245943/59 [====================>.........] - ETA: 1s - loss: 0.246844/59 [=====================>........] - ETA: 1s - loss: 0.246645/59 [=====================>........] - ETA: 0s - loss: 0.246646/59 [======================>.......] - ETA: 0s - loss: 0.246947/59 [======================>.......] - ETA: 0s - loss: 0.246348/59 [=======================>......] - ETA: 0s - loss: 0.245949/59 [=======================>......] - ETA: 0s - loss: 0.246250/59 [========================>.....] - ETA: 0s - loss: 0.246751/59 [========================>.....] - ETA: 0s - loss: 0.247752/59 [=========================>....] - ETA: 0s - loss: 0.247153/59 [=========================>....] - ETA: 0s - loss: 0.245854/59 [==========================>...] - ETA: 0s - loss: 0.245755/59 [==========================>...] - ETA: 0s - loss: 0.244856/59 [===========================>..] - ETA: 0s - loss: 0.245657/59 [===========================>..] - ETA: 0s - loss: 0.244658/59 [============================>.] - ETA: 0s - loss: 0.245459/59 [==============================] - ETA: 0s - loss: 0.246059/59 [==============================] - 4s 68ms/step - loss: 0.2460
Epoch 4/10
 1/59 [..............................] - ETA: 3s - loss: 0.2529 2/59 [>.............................] - ETA: 3s - loss: 0.2165 3/59 [>.............................] - ETA: 3s - loss: 0.2348 4/59 [=>............................] - ETA: 3s - loss: 0.2287 5/59 [=>............................] - ETA: 3s - loss: 0.2408 6/59 [==>...........................] - ETA: 3s - loss: 0.2383 7/59 [==>...........................] - ETA: 3s - loss: 0.2455 8/59 [===>..........................] - ETA: 3s - loss: 0.2438 9/59 [===>..........................] - ETA: 3s - loss: 0.236310/59 [====>.........................] - ETA: 3s - loss: 0.237411/59 [====>.........................] - ETA: 3s - loss: 0.236312/59 [=====>........................] - ETA: 3s - loss: 0.234513/59 [=====>........................] - ETA: 3s - loss: 0.230614/59 [======>.......................] - ETA: 3s - loss: 0.234815/59 [======>.......................] - ETA: 3s - loss: 0.245316/59 [=======>......................] - ETA: 3s - loss: 0.244017/59 [=======>......................] - ETA: 3s - loss: 0.238718/59 [========>.....................] - ETA: 3s - loss: 0.236419/59 [========>.....................] - ETA: 3s - loss: 0.233620/59 [=========>....................] - ETA: 3s - loss: 0.233021/59 [=========>....................] - ETA: 3s - loss: 0.232822/59 [==========>...................] - ETA: 3s - loss: 0.231023/59 [==========>...................] - ETA: 2s - loss: 0.233924/59 [===========>..................] - ETA: 2s - loss: 0.234825/59 [===========>..................] - ETA: 2s - loss: 0.236326/59 [============>.................] - ETA: 2s - loss: 0.237527/59 [============>.................] - ETA: 2s - loss: 0.234828/59 [=============>................] - ETA: 2s - loss: 0.232029/59 [=============>................] - ETA: 2s - loss: 0.231530/59 [==============>...............] - ETA: 2s - loss: 0.234731/59 [==============>...............] - ETA: 2s - loss: 0.236032/59 [===============>..............] - ETA: 2s - loss: 0.235633/59 [===============>..............] - ETA: 2s - loss: 0.235434/59 [================>.............] - ETA: 1s - loss: 0.237135/59 [================>.............] - ETA: 1s - loss: 0.235836/59 [=================>............] - ETA: 1s - loss: 0.237037/59 [=================>............] - ETA: 1s - loss: 0.236938/59 [==================>...........] - ETA: 1s - loss: 0.235939/59 [==================>...........] - ETA: 1s - loss: 0.234940/59 [===================>..........] - ETA: 1s - loss: 0.234541/59 [===================>..........] - ETA: 1s - loss: 0.234242/59 [====================>.........] - ETA: 1s - loss: 0.233543/59 [====================>.........] - ETA: 1s - loss: 0.231644/59 [=====================>........] - ETA: 1s - loss: 0.232545/59 [=====================>........] - ETA: 1s - loss: 0.233446/59 [======================>.......] - ETA: 0s - loss: 0.2336Created output folder ../outputs/1melD18T30
Executed:  cp execute_all.py ../outputs/1melD18T30
Script 0 ****************************
######### python automation/fsdd_dataset_create_label_file.py ../wav ../general #############
Script 1 ****************************
######### python feature-extraction/general_frontend.py --D 18 --T 30 --output_dir ../outputs/1melD18T30 --features mel --normalization minmax --save_plots --log_domain #############
Script 2 ****************************
######### python machine-learning/fixed_dim_encoder_clusterer.py --input_file ../outputs/1melD18T30/features_melD18T30.hdf5 --triplet_epochs 10 --epochs 10 --num_triplets 300 --super_epochs 2 --latent_dim 3 --num_classes 10 #############
